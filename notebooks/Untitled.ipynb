{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa79b1e4-5578-49f6-99d6-50055ae6146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a28c97c5-094e-404e-b79f-09147be8804e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.726248</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.109755</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.633262</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.628019</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.140043</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.795309</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.124518</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.149960</td>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1         2         3         4         5         6    7         8   \\\n",
       "0   1   1  0.459770  0.166667  0.183735  0.406802  0.309757  1.0  0.726248   \n",
       "1   1   2  0.609195  0.250000  0.283133  0.453019  0.352633  1.0  0.628019   \n",
       "2   1   3  0.252874  0.750000  0.343373  0.369523  0.370527  1.0  0.710145   \n",
       "3   1   4  0.540230  0.500000  0.343373  0.256159  0.331195  1.0  0.740741   \n",
       "4   1   5  0.390805  0.333333  0.349398  0.257467  0.404625  1.0  0.668277   \n",
       "\n",
       "         9         10        11        12        13        14        15  \\\n",
       "0  0.242424  0.109755  0.369048  0.633262  0.205882  0.199608  0.363986   \n",
       "1  0.212121  0.100242  0.380952  0.765458  0.279412  0.162813  0.411312   \n",
       "2  0.272727  0.140043  0.250000  0.795309  0.220588  0.171793  0.357445   \n",
       "3  0.318182  0.124518  0.166667  0.889126  0.294118  0.174889  0.166603   \n",
       "4  0.242424  0.149960  0.255952  0.746269  0.235294  0.174734  0.402078   \n",
       "\n",
       "         16        17        18  \n",
       "0  0.333333  0.713178  0.724662  \n",
       "1  0.333333  0.666667  0.731014  \n",
       "2  0.166667  0.627907  0.621375  \n",
       "3  0.333333  0.573643  0.662386  \n",
       "4  0.416667  0.589147  0.704502  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('../data/processed/train_FD001.txt', sep=' ', header=None)\n",
    "data_test = pd.read_csv('../data/processed/test_FD001.txt', sep=' ', header=None)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88fb9933-5ce8-487e-99a0-6e44f3178987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.726248</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.109755</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.633262</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.628019</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.140043</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.795309</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.124518</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.149960</td>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Cycles         2         3         4         5         6    7  \\\n",
       "0   1       1  0.459770  0.166667  0.183735  0.406802  0.309757  1.0   \n",
       "1   1       2  0.609195  0.250000  0.283133  0.453019  0.352633  1.0   \n",
       "2   1       3  0.252874  0.750000  0.343373  0.369523  0.370527  1.0   \n",
       "3   1       4  0.540230  0.500000  0.343373  0.256159  0.331195  1.0   \n",
       "4   1       5  0.390805  0.333333  0.349398  0.257467  0.404625  1.0   \n",
       "\n",
       "          8         9        10        11        12        13        14  \\\n",
       "0  0.726248  0.242424  0.109755  0.369048  0.633262  0.205882  0.199608   \n",
       "1  0.628019  0.212121  0.100242  0.380952  0.765458  0.279412  0.162813   \n",
       "2  0.710145  0.272727  0.140043  0.250000  0.795309  0.220588  0.171793   \n",
       "3  0.740741  0.318182  0.124518  0.166667  0.889126  0.294118  0.174889   \n",
       "4  0.668277  0.242424  0.149960  0.255952  0.746269  0.235294  0.174734   \n",
       "\n",
       "         15        16        17        18  RUL  \n",
       "0  0.363986  0.333333  0.713178  0.724662  191  \n",
       "1  0.411312  0.333333  0.666667  0.731014  190  \n",
       "2  0.357445  0.166667  0.627907  0.621375  189  \n",
       "3  0.166603  0.333333  0.573643  0.662386  188  \n",
       "4  0.402078  0.416667  0.589147  0.704502  187  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.rename(columns={0: 'ID', 1: 'Cycles'}, inplace=True)\n",
    "data_train[\"RUL\"] = data_train.groupby(\"ID\")[\"Cycles\"].transform(lambda x: x.max() - x)\n",
    "data_test.rename(columns={0: 'ID', 1: 'Cycles'}, inplace=True)\n",
    "data_test[\"RUL\"] = data_test.groupby(\"ID\")[\"Cycles\"].transform(lambda x: x.max() - x)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1ffbcb7-d836-4494-9049-3789e5c6869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUL    0\n",
      "dtype: int64 RUL    361\n",
      "dtype: int64 RUL    107.807862\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data_train[[\"RUL\"]].min(),data_train[[\"RUL\"]].max(),data_train[[\"RUL\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f1c12f3-6238-46e9-ba29-5c4ca65f83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 30\n",
    "def create_Sets(data_train, window_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "    # Agrupamos por ID de motor\n",
    "    for j, group in data_train.groupby(\"ID\"):\n",
    "        group = group.sort_values(\"Cycles\")\n",
    "        features = group.iloc[:, 2:-1].values  # columnas 2 hasta penúltima (sin ID, Cycles, ni RUL)\n",
    "        rul_values = group[\"RUL\"].values\n",
    "        \n",
    "        if len(group) >= window_size:\n",
    "            for i in range(len(group) - window_size + 1):\n",
    "                X.append(features[i:i + window_size])\n",
    "                Y.append(rul_values[i + window_size - 1])\n",
    "        else:\n",
    "            print(f\"Warning: Unit {j} has less than {window_size} cycles\")\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(Y[:, None], dtype=torch.float32)\n",
    "X_train, Y_train = create_Sets(data_train, window_size) \n",
    "X_test, Y_test = create_Sets(data_test, window_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9db0006e-9f6c-42ed-b22f-d17b53493247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17731, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67adace0-ae4c-410f-a168-e38468ea65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictions(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=17, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50, 1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        # extract only the last time step\n",
    "        x = x[:, -1, :]\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "896fbf7a-87a9-4092-be5e-666980255fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "Epoch 0: train RMSE 63.5278, test RMSE 49.3951\n",
      "Epoch 1: train RMSE 40.9871, test RMSE 45.6076\n",
      "Epoch 2: train RMSE 36.8801, test RMSE 45.5412\n",
      "Epoch 3: train RMSE 33.3499, test RMSE 54.0674\n",
      "Epoch 4: train RMSE 31.9285, test RMSE 50.1126\n",
      "Epoch 5: train RMSE 30.9069, test RMSE 49.1786\n",
      "Epoch 6: train RMSE 31.0170, test RMSE 49.6661\n",
      "Epoch 7: train RMSE 30.6399, test RMSE 50.2926\n",
      "Epoch 8: train RMSE 30.4820, test RMSE 53.0578\n",
      "Epoch 9: train RMSE 30.2342, test RMSE 51.0549\n",
      "Epoch 10: train RMSE 30.5898, test RMSE 52.6680\n",
      "Epoch 11: train RMSE 31.5044, test RMSE 55.6143\n",
      "Epoch 12: train RMSE 31.0242, test RMSE 55.1712\n",
      "Epoch 13: train RMSE 29.7763, test RMSE 53.8219\n",
      "Epoch 14: train RMSE 29.6835, test RMSE 49.4288\n",
      "Epoch 15: train RMSE 30.1368, test RMSE 54.6869\n",
      "Epoch 16: train RMSE 29.9295, test RMSE 49.1723\n",
      "Epoch 17: train RMSE 29.7743, test RMSE 51.6172\n",
      "Epoch 18: train RMSE 30.5621, test RMSE 46.7371\n",
      "Epoch 19: train RMSE 29.7645, test RMSE 50.9616\n",
      "Epoch 20: train RMSE 29.7116, test RMSE 48.0047\n",
      "Epoch 21: train RMSE 28.9904, test RMSE 51.0157\n",
      "Epoch 22: train RMSE 29.1672, test RMSE 51.9283\n",
      "Epoch 23: train RMSE 29.4314, test RMSE 49.9265\n",
      "Epoch 24: train RMSE 29.0041, test RMSE 53.1277\n",
      "Epoch 25: train RMSE 28.7347, test RMSE 49.5970\n",
      "Epoch 26: train RMSE 30.0619, test RMSE 46.3436\n",
      "Epoch 27: train RMSE 29.0124, test RMSE 53.9377\n",
      "Epoch 28: train RMSE 28.2921, test RMSE 49.1868\n",
      "Epoch 29: train RMSE 29.5763, test RMSE 46.3110\n",
      "Epoch 30: train RMSE 27.9776, test RMSE 48.3048\n",
      "Epoch 31: train RMSE 27.7377, test RMSE 48.7328\n",
      "Epoch 32: train RMSE 27.7029, test RMSE 50.9876\n",
      "Epoch 33: train RMSE 27.0156, test RMSE 50.2841\n",
      "Epoch 34: train RMSE 26.9756, test RMSE 50.0784\n",
      "Epoch 35: train RMSE 28.0474, test RMSE 48.7153\n",
      "Epoch 36: train RMSE 26.9339, test RMSE 50.6913\n",
      "Epoch 37: train RMSE 27.0749, test RMSE 51.2913\n",
      "Epoch 38: train RMSE 27.7058, test RMSE 53.3334\n",
      "Epoch 39: train RMSE 27.2144, test RMSE 53.3384\n",
      "Epoch 40: train RMSE 27.5725, test RMSE 51.6644\n",
      "Epoch 41: train RMSE 25.8537, test RMSE 49.9381\n",
      "Epoch 42: train RMSE 27.3019, test RMSE 47.2849\n",
      "Epoch 43: train RMSE 26.1043, test RMSE 51.6268\n",
      "Epoch 44: train RMSE 26.5254, test RMSE 48.1069\n",
      "Epoch 45: train RMSE 26.6787, test RMSE 50.8609\n",
      "Epoch 46: train RMSE 25.1943, test RMSE 50.0786\n",
      "Epoch 47: train RMSE 25.1965, test RMSE 50.2047\n",
      "Epoch 48: train RMSE 25.8077, test RMSE 49.3391\n",
      "Epoch 49: train RMSE 24.5305, test RMSE 49.7317\n",
      "Epoch 50: train RMSE 23.6770, test RMSE 48.8171\n",
      "Epoch 51: train RMSE 23.9646, test RMSE 51.3487\n",
      "Epoch 52: train RMSE 27.4919, test RMSE 51.6487\n",
      "Epoch 53: train RMSE 24.7759, test RMSE 50.9740\n",
      "Epoch 54: train RMSE 24.4164, test RMSE 45.5767\n",
      "Epoch 55: train RMSE 26.3579, test RMSE 46.0749\n",
      "Epoch 56: train RMSE 22.9991, test RMSE 47.5309\n",
      "Epoch 57: train RMSE 21.5197, test RMSE 50.8361\n",
      "Epoch 58: train RMSE 21.8682, test RMSE 48.6997\n",
      "Epoch 59: train RMSE 22.9816, test RMSE 47.0718\n",
      "Epoch 60: train RMSE 19.8535, test RMSE 50.2098\n",
      "Epoch 61: train RMSE 19.6301, test RMSE 50.5810\n",
      "Epoch 62: train RMSE 20.1998, test RMSE 50.0625\n",
      "Epoch 63: train RMSE 21.1913, test RMSE 51.3329\n",
      "Epoch 64: train RMSE 17.7457, test RMSE 49.4510\n",
      "Epoch 65: train RMSE 18.4914, test RMSE 49.2335\n",
      "Epoch 66: train RMSE 18.0883, test RMSE 49.9060\n",
      "Epoch 67: train RMSE 19.2111, test RMSE 49.1523\n",
      "Epoch 68: train RMSE 16.8655, test RMSE 49.4725\n",
      "Epoch 69: train RMSE 17.2574, test RMSE 47.8047\n",
      "Epoch 70: train RMSE 18.8081, test RMSE 49.2386\n",
      "Epoch 71: train RMSE 17.2463, test RMSE 49.7247\n",
      "Epoch 72: train RMSE 16.3052, test RMSE 48.6425\n",
      "Epoch 73: train RMSE 16.8867, test RMSE 47.6604\n",
      "Epoch 74: train RMSE 16.6652, test RMSE 47.5817\n",
      "Epoch 75: train RMSE 17.0350, test RMSE 49.6948\n",
      "Epoch 76: train RMSE 20.2083, test RMSE 47.5327\n",
      "Epoch 77: train RMSE 15.8801, test RMSE 51.2892\n",
      "Epoch 78: train RMSE 15.6670, test RMSE 47.8746\n",
      "Epoch 79: train RMSE 16.1237, test RMSE 47.2435\n",
      "Epoch 80: train RMSE 14.6694, test RMSE 50.1794\n",
      "Epoch 81: train RMSE 19.3416, test RMSE 49.5029\n",
      "Epoch 82: train RMSE 29.8448, test RMSE 47.7989\n",
      "Epoch 83: train RMSE 14.6061, test RMSE 46.7994\n",
      "Epoch 84: train RMSE 15.3669, test RMSE 50.2645\n",
      "Epoch 85: train RMSE 13.5042, test RMSE 49.7703\n",
      "Epoch 86: train RMSE 13.7792, test RMSE 48.9696\n",
      "Epoch 87: train RMSE 12.9445, test RMSE 48.3797\n",
      "Epoch 88: train RMSE 17.6218, test RMSE 48.8273\n",
      "Epoch 89: train RMSE 14.0880, test RMSE 47.4022\n",
      "Epoch 90: train RMSE 13.3281, test RMSE 48.4165\n",
      "Epoch 91: train RMSE 21.6040, test RMSE 49.2304\n",
      "Epoch 92: train RMSE 13.6323, test RMSE 48.7549\n",
      "Epoch 93: train RMSE 13.1182, test RMSE 49.6224\n",
      "Epoch 94: train RMSE 14.3736, test RMSE 47.1530\n",
      "Epoch 95: train RMSE 11.9975, test RMSE 46.6752\n",
      "Epoch 96: train RMSE 13.3514, test RMSE 49.6677\n",
      "Epoch 97: train RMSE 14.2959, test RMSE 49.1742\n",
      "Epoch 98: train RMSE 11.3486, test RMSE 48.9202\n",
      "Epoch 99: train RMSE 11.3314, test RMSE 47.8191\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando dispositivo:\", device)\n",
    "\n",
    "model = Predictions().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "Y_test = Y_test.to(device)\n",
    "\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, Y_train), shuffle=True, batch_size=8)\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        train_rmse = torch.sqrt(loss_fn(y_pred, Y_train)).item()\n",
    "        y_pred = model(X_test)\n",
    "        test_rmse = torch.sqrt(loss_fn(y_pred, Y_test)).item()\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f183a2b-59a0-4a72-bcc8-c08e3a7b7207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
